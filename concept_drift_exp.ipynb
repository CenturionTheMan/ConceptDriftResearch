{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNnASzDJAvfAKabVkgUkpC3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["REMOVE_RES_CONTENT = True\n","SEED = 42\n","\n","RES_PATH = '/content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/'"],"metadata":{"id":"jnW2ICuewM0-","executionInfo":{"status":"ok","timestamp":1752753159941,"user_tz":-120,"elapsed":2,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":145,"outputs":[]},{"cell_type":"code","execution_count":146,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFFQKC56qsb-","executionInfo":{"status":"ok","timestamp":1752753162205,"user_tz":-120,"elapsed":2248,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"4ed29e1e-c08c-4ca9-98f7-a61457c3b548"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Pliki już są rozpakowane — pomijam kopiowanie i rozpakowywanie.\n","total 890M\n","drwxrwxr-x 4 root root 4.0K Jul 16 20:22 data\n","-rw------- 1 root root 890M Jul 17 10:51 data.zip\n","drwx------ 6 root root 4.0K Jul 17 10:51 drive\n","drwxr-xr-x 2 root root 4.0K Jul 17 10:52 res\n","drwxr-xr-x 1 root root 4.0K Jul 15 13:41 sample_data\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# Montuj Google Drive (tylko raz)\n","drive.mount('/content/drive')\n","\n","# Ścieżki\n","zip_path = '/content/data.zip'\n","dataset_dir = '/content/'\n","zip_on_drive = '/content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/data.zip'\n","\n","# Sprawdź, czy katalog z danymi już istnieje\n","if not os.path.exists(dataset_dir+'data') or len(os.listdir(dataset_dir)) == 0:\n","    print(\"Pliki jeszcze nie wypakowane — kopiuję i rozpakowuję...\")\n","    # Skopiuj zip z Drive do RAM\n","    if not os.path.exists(zip_path):\n","        !cp \"$zip_on_drive\" \"$zip_path\"\n","    # Rozpakuj zip\n","    !unzip -q \"$zip_path\" -d \"$dataset_dir\"\n","else:\n","    print(\"Pliki już są rozpakowane — pomijam kopiowanie i rozpakowywanie.\")\n","\n","# Podejrzyj zawartość\n","!ls -lh \"$dataset_dir\"\n"]},{"cell_type":"code","source":["!pip install -q fairlearn tabulate\n","\n","import pandas as pd\n","import numpy as np\n","import tabulate as tb\n","from typing import Dict\n","import tensorflow as tf\n","import re\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score, f1_score\n","from tensorflow.keras.applications import MobileNetV2\n","from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n","from tensorflow.keras.applications import Xception, EfficientNetB0, ResNet50\n","import os\n","import shutil\n","\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","# Informacja o dostępności GPU\n","device_name = tf.test.gpu_device_name()\n","if device_name:\n","    print(f\"GPU jest dostępne: {device_name}\")\n","else:\n","    print(\"GPU NIE jest dostępne, sprawdź ustawienia środowiska\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPKtaDEKrVlM","executionInfo":{"status":"ok","timestamp":1752753166142,"user_tz":-120,"elapsed":3935,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"9461a8f3-eaa7-4cbe-87ac-92cbc0e3374e"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU jest dostępne: /device:GPU:0\n"]}]},{"cell_type":"code","source":["file_path = '/content/data/metadata.csv'\n","df_tmp = pd.read_csv(file_path, sep=',')\n","df_tmp['path'] = '/content/data/' + df_tmp['path']\n","\n","df_tmp = df_tmp[df_tmp['deepfake'] != 0]\n","\n","df_tmp['ethnicity'] = df_tmp.apply(\n","    lambda row: 'white' if row['white'] == 1 else ('black' if row['black'] == 1 else (\n","        'asian' if row['asian'] == 1 else None)), axis=1)\n","\n","df = df_tmp[['deepfake', 'male', 'ethnicity', 'eyeglasses', 'heavy_makeup', 'big_lips', 'path']]\n","\n","df = df.rename(columns={'deepfake': 'type', 'male': 'sex', 'heavy_makeup': 'makeup', 'big_lips': 'lips',})\n","\n","df['type'] = df['type'].replace({1: 'fake', -1: 'real'})\n","df['sex'] = df['sex'].replace({-1: 'female', 0: None, 1: 'male'})\n","df['makeup'] = df['makeup'].replace({-1: 'no', 0: None, 1: 'yes'})\n","df['lips'] = df['lips'].replace({-1: 'small', 0: None, 1: 'big'})\n","df['eyeglasses'] = df['eyeglasses'].replace({-1: 'no', 0: None, 1: 'yes'})\n","\n","\n","print(tb.tabulate(df.head(), headers='keys', tablefmt='psql'))\n","print(f\"Dataset size: {len(df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQHjq4DXrY3h","executionInfo":{"status":"ok","timestamp":1752753167049,"user_tz":-120,"elapsed":891,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"a32ec58a-a878-4433-a3a0-cf95a05bb3bb"},"execution_count":148,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------+\n","|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                    |\n","|----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------|\n","|  0 | real   | male   |             | yes          | no       | big    | /content/data/original/805/frame271.jpg |\n","|  1 | real   | female | white       | no           |          | big    | /content/data/original/083/frame191.jpg |\n","|  2 | real   | male   | white       | no           | no       | small  | /content/data/original/878/frame111.jpg |\n","|  3 | real   | female | white       | no           |          |        | /content/data/original/158/frame201.jpg |\n","|  4 | real   | female | white       | no           |          |        | /content/data/original/606/frame71.jpg  |\n","+----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------+\n","Dataset size: 59552\n"]}]},{"cell_type":"code","source":["def get_balanced_subset(\n","    df, class_col, feature_col, feature_value,\n","    samples_per_class, randomize=True, reset_index=False\n","):\n","    \"\"\"\n","    Select a balanced subset of the data for a given feature value, with equal number of samples per class.\n","\n","    Args:\n","        df: DataFrame\n","        class_col: column name of class labels\n","        feature_col: column name of feature\n","        feature_value: specific feature value to filter\n","        samples_per_class: number of samples per class\n","        randomize: whether to shuffle within class before selecting\n","        reset_index: whether to reset index of returned DataFrame\n","        seed: random seed for reproducibility\n","\n","    Returns:\n","        Balanced DataFrame subset\n","    \"\"\"\n","    tmp = df[df[feature_col] == feature_value]\n","\n","    counts = tmp[class_col].value_counts()\n","    for cl, count in counts.items():\n","        if count < samples_per_class:\n","            raise ValueError(f\"Not enough samples for class '{cl}' in feature '{feature_value}'. \"\n","                             f\"Required: {samples_per_class}, Available: {count}\")\n","\n","    tmp = pd.concat([\n","        (g.sample(frac=1, random_state=SEED).head(samples_per_class) if randomize else g.head(samples_per_class))\n","        for _, g in tmp.groupby(class_col)\n","    ])\n","\n","    if reset_index:\n","        tmp = tmp.reset_index(drop=True)\n","\n","    return tmp\n","\n","tmp_test = get_balanced_subset(\n","    df=df, class_col='type', feature_col='sex', feature_value='male',\n","    samples_per_class=2, randomize=True, reset_index=True)\n","print(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqJXku-tsxK7","executionInfo":{"status":"ok","timestamp":1752753167076,"user_tz":-120,"elapsed":21,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"1140a240-006f-434a-c0b8-6071656718d3"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------+\n","|    | type   | sex   | ethnicity   | eyeglasses   | makeup   | lips   | path                                        |\n","|----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------|\n","|  0 | fake   | male  | white       | no           | no       | small  | /content/data/deepfake/374_407/frame41.jpg  |\n","|  1 | fake   | male  | white       | no           | no       | small  | /content/data/deepfake/015_919/frame281.jpg |\n","|  2 | real   | male  |             | no           | no       | big    | /content/data/original/995/frame11.jpg      |\n","|  3 | real   | male  | white       | no           | no       |        | /content/data/original/579/frame201.jpg     |\n","+----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------+\n"]}]},{"cell_type":"code","source":["def get_exp_data(df, class_col, feature_col, ratio : Dict, size, randomize=True, exclude_column=None, exclude_df=None, max_diff=0.05):\n","    '''\n","    Get a balanced subset of the data based on specified ratios for features.\n","    Args:\n","        df: DataFrame containing the data\n","        class_col: column name for class labels\n","        feature_col: column name for features\n","        ratio: dictionary with feature values as keys and their ratios as values\n","        size: total number of samples to return\n","        randomize: whether to shuffle the DataFrame before processing\n","        exclude_column: column name to exclude from the DataFrame\n","        exclude_df: DataFrame containing values to exclude based on exclude_column\n","    '''\n","    if randomize:\n","        df_rnd = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","    else:\n","        df_rnd = df.copy()\n","\n","    if exclude_column is not None and exclude_df is not None:\n","        if exclude_column not in df_rnd.columns:\n","            raise ValueError(f\"Column '{exclude_column}' not found in DataFrame.\")\n","        if exclude_column not in exclude_df.columns:\n","            raise ValueError(f\"Column '{exclude_column}' not found in exclude DataFrame.\")\n","        df_rnd = df_rnd[~df_rnd[exclude_column].isin(exclude_df[exclude_column])]\n","\n","    uniq_classes = df_rnd[class_col].unique()\n","    uniq_features = df_rnd[feature_col].unique()\n","\n","    def get_exp_data_inner(tmp_df, size):\n","        df_tmp = None\n","        for uf in uniq_features:\n","            if ratio.get(uf) is None:\n","                print(f\"Feature '{uf}' not found in ratios. Skipping.\")\n","                continue\n","            c_amt = int(size * ratio[uf] / len(uniq_classes))\n","            # if c_amt <= 0:\n","            #     raise ValueError(f\"Calculated samples per class ({c_amt}) is less than or equal to zero for feature '{uf}' with ratio {ratio}.\")\n","            tmp = get_balanced_subset(df=tmp_df, class_col=class_col, feature_col=feature_col, feature_value=uf,\n","                                        samples_per_class=c_amt, randomize=False)\n","            if df_tmp is None:\n","                df_tmp = tmp\n","            else:\n","                df_tmp = pd.concat([df_tmp, tmp])\n","        return df_tmp\n","\n","    df_res = get_exp_data_inner(df_rnd, size)\n","\n","    if len(df_res) < size:\n","        print(f\"Samples for ({len(df_res)}) are less than requested ({size}).\")\n","\n","    ratios_fet = df_res[feature_col].value_counts(normalize=True).to_dict()\n","    ratios_cls = df_res[class_col].value_counts(normalize=False).to_dict()\n","    print(f\"[] Ratios for {feature_col}: {ratios_fet}\")\n","    print(f\"[] Ratios for {class_col}: {ratios_cls}\")\n","\n","    for k in ratio:\n","        if ratios_fet.get(k) is None:\n","            if ratio[k] > 0.0:\n","                raise ValueError(f\"Feature '{k}' not found in DataFrame after sampling (try increase 'size' parameter).\")\n","        elif abs(ratios_fet[k] - ratio[k]) > max_diff:\n","            raise ValueError(f\"Feature '{k}' ratio {ratios_fet[k]} differs from requested {ratio[k]} by more than {max_diff}.\")\n","\n","    print()\n","\n","    df_res = df_res.reset_index(drop=True)\n","\n","    return df_res\n","\n","tmp_test = get_exp_data(\n","    df=df, class_col='type', feature_col='ethnicity', ratio={'white':0.2, 'black':0.6, 'asian': 0.2}, size=10, randomize=True)\n","print(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJZmhWnis0yh","executionInfo":{"status":"ok","timestamp":1752753167136,"user_tz":-120,"elapsed":52,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"4ef6bb1f-b9ef-4bff-f16b-46552fcf2d21"},"execution_count":150,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature 'None' not found in ratios. Skipping.\n","[] Ratios for ethnicity: {'black': 0.6, 'white': 0.2, 'asian': 0.2}\n","[] Ratios for type: {'fake': 5, 'real': 5}\n","\n","+----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------+\n","|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                        |\n","|----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------|\n","|  0 | fake   | male   | white       | no           | no       | small  | /content/data/deepfake/594_530/frame121.jpg |\n","|  1 | real   | female | white       | no           |          |        | /content/data/original/240/frame41.jpg      |\n","|  2 | fake   | female | asian       |              |          | big    | /content/data/deepfake/249_280/frame261.jpg |\n","|  3 | real   | female | asian       | no           |          | big    | /content/data/original/758/frame161.jpg     |\n","|  4 | fake   | female | black       | no           |          | big    | /content/data/deepfake/986_994/frame271.jpg |\n","|  5 | fake   | male   | black       | no           | no       | big    | /content/data/deepfake/144_122/frame101.jpg |\n","|  6 | fake   | male   | black       | yes          | no       | big    | /content/data/deepfake/081_087/frame41.jpg  |\n","|  7 | real   | male   | black       | no           | no       | big    | /content/data/original/715/frame231.jpg     |\n","|  8 | real   | female | black       | no           |          | big    | /content/data/original/762/frame61.jpg      |\n","|  9 | real   | female | black       | no           |          | big    | /content/data/original/328/frame241.jpg     |\n","+----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------+\n"]}]},{"cell_type":"code","source":["def load_image(file_path, target_size=(224, 224)):\n","    image = tf.io.read_file(file_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, target_size)\n","    image = image / 255.0  # Normalize to [0, 1]\n","    return image\n","\n","def get_data_for_model(df, class_col, files_col, batch_size):\n","    image_paths = df[files_col].values\n","    labels = df[class_col].values\n","    labels = df[class_col].astype('category').cat.codes.values #classes strs to ints\n","    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n","    dataset = dataset.map(lambda path, label: (load_image(path), label))\n","    dataset = dataset.batch(batch_size)\n","    return dataset"],"metadata":{"id":"LNCRWX5js2d7","executionInfo":{"status":"ok","timestamp":1752753167140,"user_tz":-120,"elapsed":3,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":151,"outputs":[]},{"cell_type":"code","source":["def create_mobile_net2(num_classes, input_shape=(224, 224, 3)):\n","    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model, \"mobile net 2\"\n","\n","def create_resnet50(num_classes, input_shape=(224, 224, 3)):\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model, \"resnet50\"\n","\n","def create_efficientnet_b0(num_classes, input_shape=(224, 224, 3)):\n","    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model, \"efficientnet b0\"\n","\n","# def create_xception(num_classes, input_shape=(299, 299, 3)):\n","def create_xception(num_classes, input_shape=(224, 224, 3)):\n","    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model, \"xception\""],"metadata":{"id":"_cfHfqsPvi3O","executionInfo":{"status":"ok","timestamp":1752753167157,"user_tz":-120,"elapsed":16,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# Create folder if it doesn't exist\n","if not os.path.exists(RES_PATH):\n","    os.makedirs(RES_PATH)\n","    print(f\"Created folder: {RES_PATH}\")\n","elif REMOVE_RES_CONTENT:\n","    # Remove all files inside the folder\n","    for filename in os.listdir(RES_PATH):\n","        file_path = os.path.join(RES_PATH, filename)\n","        try:\n","            if os.path.isfile(file_path) or os.path.islink(file_path):\n","                os.unlink(file_path)          # remove file or link\n","            elif os.path.isdir(file_path):\n","                shutil.rmtree(file_path)      # remove folder and contents\n","        except Exception as e:\n","            print(f'Failed to delete {file_path}. Reason: {e}')\n","    print(f\"Cleared contents of folder: {RES_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYJbzSoMv9Vd","executionInfo":{"status":"ok","timestamp":1752753167184,"user_tz":-120,"elapsed":25,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"c08cd5cc-ac41-4f31-f920-3dd10e93f6d6"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleared contents of folder: /content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/\n"]}]},{"cell_type":"code","source":["def get_done_reps(model_name, amt_per_rep):\n","  results_path = f'{RES_PATH}res_{model_name.replace(\" \", \"_\")}.csv'\n","  if not os.path.exists(results_path):\n","    return [], None\n","\n","  tmp_df = pd.read_csv(results_path)\n","  dones = []\n","  for r in tmp_df[\"rep\"].unique():\n","    amt = len(tmp_df[tmp_df[\"rep\"]==r])\n","    if amt == amt_per_rep:\n","      dones.append(r)\n","\n","  return dones, tmp_df\n","\n"],"metadata":{"id":"CQ_JQedB1623","executionInfo":{"status":"ok","timestamp":1752753167216,"user_tz":-120,"elapsed":30,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":154,"outputs":[]},{"cell_type":"code","source":["def perform_tests(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num, batch_size):\n","    res = []\n","\n","    _, model_name = get_model(num_classes=len(df[class_col].unique()))\n","\n","    done_reps, prev_results = get_done_reps(model_name, len(test_metas) * len(train_metas))\n","\n","    for r in range(reps):\n","        if r in done_reps:\n","          res.extend(prev_results[prev_results['rep']==r].values.tolist())\n","          print(f\"Rep {r} already done for {model_name}. Skipping...\")\n","          continue\n","\n","        np.random.seed(SEED + r)\n","        tf.random.set_seed(SEED + r)\n","\n","        for train_meta in train_metas:\n","            train = get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=train_meta['ratio'], size=train_meta['size'])\n","            train = train.sample(frac=1, random_state=SEED+r).reset_index(drop=True)\n","\n","            tests = [\n","                get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=tm['ratio'], size=tm['size'], exclude_column=exclude_column, exclude_df=train) for tm in test_metas\n","            ]\n","\n","            train_dataset = get_data_for_model(train, class_col=class_col, files_col=files_col, batch_size=batch_size)\n","            test_datasets = [\n","                get_data_for_model(test, class_col=class_col, files_col=files_col, batch_size=batch_size) for test in tests\n","            ]\n","\n","            train_ratio = '/'.join([f\"{k}:{v}\" for k, v in train_meta['ratio'].items()])\n","            train_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in train[feature_split_col].value_counts(normalize=True).to_dict().items()])\n","            train_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', train_ratio)\n","\n","            model, model_name = get_model(num_classes=len(df[class_col].unique()))\n","            model.fit(train_dataset, epochs=epochs_num)\n","\n","            for test_dataset, test_meta, test_df in zip(test_datasets, test_metas, tests):\n","                predictions = model.predict(test_dataset)\n","                y_true = test_df[class_col].astype('category').cat.codes.values\n","                y_pred = np.argmax(predictions, axis=1)\n","                acc = accuracy_score(y_true, y_pred)\n","                f1 = f1_score(y_true, y_pred, average='weighted')\n","                eo_diff = equalized_odds_difference(y_true, y_pred, sensitive_features=test_df[feature_split_col])\n","\n","                test_ratio = '/'.join([f\"{k}:{v}\" for k, v in test_meta['ratio'].items()])\n","                test_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in test_df[feature_split_col].value_counts(normalize=True).to_dict().items()])\n","                test_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', test_ratio)\n","\n","                res.append([\n","                    r,\n","                    model_name,\n","                    feature_split_col,\n","                    train_meta['size'],\n","                    train_ratio,\n","                    test_meta['size'],\n","                    test_ratio,\n","                    acc,\n","                    f1,\n","                    eo_diff,\n","                    train_ratio_rel,\n","                    test_ratio_rel,\n","                    train_ratio_sim,\n","                    test_ratio_sim\n","                ])\n","\n","                print(f\"Rep: {r:2} | Model: {model_name} | Feature Split: {feature_split_col} | Ratio: {test_ratio} | Acc: {acc:.2f}\")\n","\n","                res_df = pd.DataFrame(res, columns=[\n","                    'rep', 'model_name', 'feature_split_col',\n","                    'train_size', 'train_ratio_detail', 'test_size', 'test_ratio_detail',\n","                    'accuracy', 'f1_score', 'eo_diff', 'train_ratio_rel', 'test_ratio_rel', \"train_ratio\", \"test_ratio\"\n","                ])\n","\n","                res_df.to_csv(f'{RES_PATH}res_{model_name.replace(\" \", \"_\")}.csv', index=False)\n","    print(f\"Done for {model_name}.\")\n",""],"metadata":{"id":"ik6Z-AUis6G7","executionInfo":{"status":"ok","timestamp":1752753167220,"user_tz":-120,"elapsed":2,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["perform_tests(df=df,\n","              train_metas=[\n","                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 10000},\n","                  ],\n","              test_metas=[\n","                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 1000},\n","                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 1000},\n","                  {'ratio': {'male':0.9, 'female':0.1}, 'size': 1000},\n","              ],\n","              reps=2,\n","              class_col='type',\n","              feature_split_col='sex',\n","              exclude_column='path',\n","              files_col='path',\n","              get_model=create_xception,\n","              epochs_num=10,\n","              batch_size=32\n","              )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yM2K_awwwv2m","executionInfo":{"status":"error","timestamp":1752753943011,"user_tz":-120,"elapsed":775790,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}},"outputId":"c86d48e4-46d3-4a67-99fc-9db374dd2ab0"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n","[] Ratios for type: {'fake': 5000, 'real': 5000}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'male': 0.5, 'female': 0.5}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'male': 0.9, 'female': 0.1}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Epoch 1/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 143ms/step - accuracy: 0.5183 - loss: 0.7218\n","Epoch 2/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 129ms/step - accuracy: 0.5370 - loss: 0.6884\n","Epoch 3/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.5630 - loss: 0.6799\n","Epoch 4/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 126ms/step - accuracy: 0.5823 - loss: 0.6706\n","Epoch 5/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 125ms/step - accuracy: 0.6088 - loss: 0.6580\n","Epoch 6/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 124ms/step - accuracy: 0.6241 - loss: 0.6415\n","Epoch 7/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 0.6439 - loss: 0.6228\n","Epoch 8/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 124ms/step - accuracy: 0.6600 - loss: 0.6060\n","Epoch 9/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 0.6704 - loss: 0.5908\n","Epoch 10/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 124ms/step - accuracy: 0.6852 - loss: 0.5771\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 256ms/step\n","Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.1/female:0.9 | Acc: 0.60\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step\n","Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.57\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step\n","Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.9/female:0.1 | Acc: 0.53\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n","[] Ratios for type: {'fake': 5000, 'real': 5000}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'male': 0.5, 'female': 0.5}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Feature 'None' not found in ratios. Skipping.\n","[] Ratios for sex: {'male': 0.9, 'female': 0.1}\n","[] Ratios for type: {'fake': 500, 'real': 500}\n","\n","Epoch 1/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 132ms/step - accuracy: 0.5156 - loss: 0.7041\n","Epoch 2/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 127ms/step - accuracy: 0.5492 - loss: 0.6831\n","Epoch 3/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 123ms/step - accuracy: 0.5675 - loss: 0.6763\n","Epoch 4/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 124ms/step - accuracy: 0.6019 - loss: 0.6589\n","Epoch 5/10\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 125ms/step - accuracy: 0.6289 - loss: 0.6454\n","Epoch 6/10\n","\u001b[1m 74/313\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.6700 - loss: 0.6142"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-156-1069249157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m perform_tests(df=df, \n\u001b[0m\u001b[1;32m      2\u001b[0m               train_metas=[\n\u001b[1;32m      3\u001b[0m                   \u001b[0;34m{\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'male'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'female'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   ],\n\u001b[1;32m      5\u001b[0m               test_metas=[\n","\u001b[0;32m/tmp/ipython-input-155-3708175670.py\u001b[0m in \u001b[0;36mperform_tests\u001b[0;34m(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["def print_summarise_res(model_name:str):\n","  path = RES_PATH + f'res_{model_name}.csv'\n","\n","  if not os.path.exists(path):\n","    print(f\"File {path} does not exists!\")\n","    return\n","\n","  res = pd.read_csv(path)\n","  gr = res.groupby(['train_ratio', 'test_ratio']).agg(\n","      # Model=('model_name', 'first'),\n","      TrainRatio=('train_ratio', 'first'),\n","      TestRatio=('test_ratio', 'first'),\n","      Accuracy= ('accuracy', 'mean'),\n","      AccuracySTD= ('accuracy', 'std'),\n","      F1=('f1_score', 'mean'),\n","      F1STD=('f1_score', 'std'),\n","      EODiff=('eo_diff', 'mean'),\n","      EODiffSTD=('eo_diff', 'std'),\n","  ).reset_index(drop=True)\n","\n","  gr = gr.round(3).sort_values(by=['TrainRatio', 'TestRatio'], ascending=False)\n","\n","  print(\"MODEL: \" + model_name)\n","  print(tb.tabulate(gr, headers='keys', tablefmt='psql'))\n","  print()\n","  print()\n","\n","print_summarise_res('resnet50')\n","print_summarise_res('efficientnet_b0')\n","print_summarise_res('xception')"],"metadata":{"id":"ivm4W_DLs7jK","executionInfo":{"status":"aborted","timestamp":1752753943057,"user_tz":-120,"elapsed":41,"user":{"displayName":"Michał Dziedziak","userId":"05297868277716799551"}}},"execution_count":null,"outputs":[]}]}