{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOG6x5ixYEEYYnStWW+WLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CenturionTheMan/ConceptDriftResearch/blob/main/concept_drift_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REMOVE_RES_CONTENT = True\n",
        "# IMG_SIZE=299\n",
        "IMG_SIZE=224\n",
        "DATA_ZIP_PATH=f'/content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/data{IMG_SIZE}.zip'\n",
        "IMG_RESIZE = False\n",
        "SEED = 42\n",
        "RES_PATH = '/content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/'"
      ],
      "metadata": {
        "id": "jnW2ICuewM0-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFFQKC56qsb-",
        "outputId": "623e005d-58d9-4608-d03f-bb726b8ccbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Pliki jeszcze nie wypakowane — kopiuję i rozpakowuję...\n",
            "total 890M\n",
            "drwxrwxr-x 4 root root 4.0K Jul 16 20:22 data\n",
            "-rw------- 1 root root 890M Jul 17 14:25 data.zip\n",
            "drwx------ 6 root root 4.0K Jul 17 14:01 drive\n",
            "drwxrwxrwx 4 root root 4.0K Jul 17 13:14 OLD\n",
            "drwxr-xr-x 1 root root 4.0K Jul 15 13:41 sample_data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montuj Google Drive (tylko raz)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ścieżki\n",
        "zip_path = '/content/data.zip'\n",
        "dataset_dir = '/content/'\n",
        "zip_on_drive = DATA_ZIP_PATH\n",
        "\n",
        "# Sprawdź, czy katalog z danymi już istnieje\n",
        "if not os.path.exists(dataset_dir+'data') or len(os.listdir(dataset_dir)) == 0:\n",
        "    print(\"Pliki jeszcze nie wypakowane — kopiuję i rozpakowuję...\")\n",
        "    # Skopiuj zip z Drive do RAM\n",
        "    if not os.path.exists(zip_path):\n",
        "        !cp \"$zip_on_drive\" \"$zip_path\"\n",
        "    # Rozpakuj zip\n",
        "    !unzip -q \"$zip_path\" -d \"$dataset_dir\"\n",
        "else:\n",
        "    print(\"Pliki już są rozpakowane — pomijam kopiowanie i rozpakowywanie.\")\n",
        "\n",
        "# Podejrzyj zawartość\n",
        "!ls -lh \"$dataset_dir\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fairlearn tabulate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tabulate as tb\n",
        "from typing import Dict\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
        "from tensorflow.keras.applications import Xception, EfficientNetB0, ResNet50\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Informacja o dostępności GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name:\n",
        "    print(f\"GPU jest dostępne: {device_name}\")\n",
        "else:\n",
        "    print(\"GPU NIE jest dostępne, sprawdź ustawienia środowiska\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPKtaDEKrVlM",
        "outputId": "22c42d6e-675e-4325-fc21-09fa19ba8c26"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU jest dostępne: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/data/metadata.csv'\n",
        "df_tmp = pd.read_csv(file_path, sep=',')\n",
        "df_tmp['path'] = '/content/data/' + df_tmp['path']\n",
        "\n",
        "df_tmp = df_tmp[df_tmp['deepfake'] != 0]\n",
        "\n",
        "df_tmp['ethnicity'] = df_tmp.apply(\n",
        "    lambda row: 'white' if row['white'] == 1 else ('black' if row['black'] == 1 else (\n",
        "        'asian' if row['asian'] == 1 else None)), axis=1)\n",
        "\n",
        "df = df_tmp[['deepfake', 'male', 'ethnicity', 'eyeglasses', 'heavy_makeup', 'big_lips', 'path']]\n",
        "\n",
        "df = df.rename(columns={'deepfake': 'type', 'male': 'sex', 'heavy_makeup': 'makeup', 'big_lips': 'lips',})\n",
        "\n",
        "df['type'] = df['type'].replace({1: 'fake', -1: 'real'})\n",
        "df['sex'] = df['sex'].replace({-1: 'female', 0: None, 1: 'male'})\n",
        "df['makeup'] = df['makeup'].replace({-1: 'no', 0: None, 1: 'yes'})\n",
        "df['lips'] = df['lips'].replace({-1: 'small', 0: None, 1: 'big'})\n",
        "df['eyeglasses'] = df['eyeglasses'].replace({-1: 'no', 0: None, 1: 'yes'})\n",
        "\n",
        "\n",
        "print(tb.tabulate(df.head(), headers='keys', tablefmt='psql'))\n",
        "print(f\"Dataset size: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQHjq4DXrY3h",
        "outputId": "af21d415-0ab1-4bc3-df0c-7963f163abbf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------+\n",
            "|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                    |\n",
            "|----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------|\n",
            "|  0 | real   | male   |             | yes          | no       | big    | /content/data/original/805/frame271.jpg |\n",
            "|  1 | real   | female | white       | no           |          | big    | /content/data/original/083/frame191.jpg |\n",
            "|  2 | real   | male   | white       | no           | no       | small  | /content/data/original/878/frame111.jpg |\n",
            "|  3 | real   | female | white       | no           |          |        | /content/data/original/158/frame201.jpg |\n",
            "|  4 | real   | female | white       | no           |          |        | /content/data/original/606/frame71.jpg  |\n",
            "+----+--------+--------+-------------+--------------+----------+--------+-----------------------------------------+\n",
            "Dataset size: 59552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_subset(\n",
        "    df, class_col, feature_col, feature_value,\n",
        "    samples_per_class, randomize=True, reset_index=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Select a balanced subset of the data for a given feature value, with equal number of samples per class.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame\n",
        "        class_col: column name of class labels\n",
        "        feature_col: column name of feature\n",
        "        feature_value: specific feature value to filter\n",
        "        samples_per_class: number of samples per class\n",
        "        randomize: whether to shuffle within class before selecting\n",
        "        reset_index: whether to reset index of returned DataFrame\n",
        "        seed: random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        Balanced DataFrame subset\n",
        "    \"\"\"\n",
        "    tmp = df[df[feature_col] == feature_value]\n",
        "\n",
        "    counts = tmp[class_col].value_counts()\n",
        "    for cl, count in counts.items():\n",
        "        if count < samples_per_class:\n",
        "            raise ValueError(f\"Not enough samples for class '{cl}' in feature '{feature_value}'. \"\n",
        "                             f\"Required: {samples_per_class}, Available: {count}\")\n",
        "\n",
        "    tmp = pd.concat([\n",
        "        (g.sample(frac=1, random_state=SEED).head(samples_per_class) if randomize else g.head(samples_per_class))\n",
        "        for _, g in tmp.groupby(class_col)\n",
        "    ])\n",
        "\n",
        "    if reset_index:\n",
        "        tmp = tmp.reset_index(drop=True)\n",
        "\n",
        "    return tmp\n",
        "\n",
        "tmp_test = get_balanced_subset(\n",
        "    df=df, class_col='type', feature_col='sex', feature_value='male',\n",
        "    samples_per_class=2, randomize=True, reset_index=True)\n",
        "print(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqJXku-tsxK7",
        "outputId": "f90c17ea-a025-4724-d8c6-d72c5fd6fc07"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------+\n",
            "|    | type   | sex   | ethnicity   | eyeglasses   | makeup   | lips   | path                                        |\n",
            "|----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------|\n",
            "|  0 | fake   | male  | white       | no           | no       | small  | /content/data/deepfake/374_407/frame41.jpg  |\n",
            "|  1 | fake   | male  | white       | no           | no       | small  | /content/data/deepfake/015_919/frame281.jpg |\n",
            "|  2 | real   | male  |             | no           | no       | big    | /content/data/original/995/frame11.jpg      |\n",
            "|  3 | real   | male  | white       | no           | no       |        | /content/data/original/579/frame201.jpg     |\n",
            "+----+--------+-------+-------------+--------------+----------+--------+---------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_exp_data(df, class_col, feature_col, ratio : Dict, size, randomize=True, exclude_column=None, exclude_df=None, max_diff=0.05):\n",
        "    '''\n",
        "    Get a balanced subset of the data based on specified ratios for features.\n",
        "    Args:\n",
        "        df: DataFrame containing the data\n",
        "        class_col: column name for class labels\n",
        "        feature_col: column name for features\n",
        "        ratio: dictionary with feature values as keys and their ratios as values\n",
        "        size: total number of samples to return\n",
        "        randomize: whether to shuffle the DataFrame before processing\n",
        "        exclude_column: column name to exclude from the DataFrame\n",
        "        exclude_df: DataFrame containing values to exclude based on exclude_column\n",
        "    '''\n",
        "    if randomize:\n",
        "        df_rnd = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "    else:\n",
        "        df_rnd = df.copy()\n",
        "\n",
        "    if exclude_column is not None and exclude_df is not None:\n",
        "        if exclude_column not in df_rnd.columns:\n",
        "            raise ValueError(f\"Column '{exclude_column}' not found in DataFrame.\")\n",
        "        if exclude_column not in exclude_df.columns:\n",
        "            raise ValueError(f\"Column '{exclude_column}' not found in exclude DataFrame.\")\n",
        "        df_rnd = df_rnd[~df_rnd[exclude_column].isin(exclude_df[exclude_column])]\n",
        "\n",
        "    uniq_classes = df_rnd[class_col].unique()\n",
        "    uniq_features = df_rnd[feature_col].unique()\n",
        "\n",
        "    def get_exp_data_inner(tmp_df, size):\n",
        "        df_tmp = None\n",
        "        for uf in uniq_features:\n",
        "            if ratio.get(uf) is None:\n",
        "                print(f\"Feature '{uf}' not found in ratios. Skipping.\")\n",
        "                continue\n",
        "            c_amt = int(size * ratio[uf] / len(uniq_classes))\n",
        "            # if c_amt <= 0:\n",
        "            #     raise ValueError(f\"Calculated samples per class ({c_amt}) is less than or equal to zero for feature '{uf}' with ratio {ratio}.\")\n",
        "            tmp = get_balanced_subset(df=tmp_df, class_col=class_col, feature_col=feature_col, feature_value=uf,\n",
        "                                        samples_per_class=c_amt, randomize=False)\n",
        "            if df_tmp is None:\n",
        "                df_tmp = tmp\n",
        "            else:\n",
        "                df_tmp = pd.concat([df_tmp, tmp])\n",
        "        return df_tmp\n",
        "\n",
        "    df_res = get_exp_data_inner(df_rnd, size)\n",
        "\n",
        "    if len(df_res) < size:\n",
        "        print(f\"Samples for ({len(df_res)}) are less than requested ({size}).\")\n",
        "\n",
        "    ratios_fet = df_res[feature_col].value_counts(normalize=True).to_dict()\n",
        "    ratios_cls = df_res[class_col].value_counts(normalize=False).to_dict()\n",
        "    print(f\"[] Ratios for {feature_col}: {ratios_fet}\")\n",
        "    print(f\"[] Ratios for {class_col}: {ratios_cls}\")\n",
        "\n",
        "    for k in ratio:\n",
        "        if ratios_fet.get(k) is None:\n",
        "            if ratio[k] > 0.0:\n",
        "                raise ValueError(f\"Feature '{k}' not found in DataFrame after sampling (try increase 'size' parameter).\")\n",
        "        elif abs(ratios_fet[k] - ratio[k]) > max_diff:\n",
        "            raise ValueError(f\"Feature '{k}' ratio {ratios_fet[k]} differs from requested {ratio[k]} by more than {max_diff}.\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    df_res = df_res.reset_index(drop=True)\n",
        "\n",
        "    return df_res\n",
        "\n",
        "tmp_test = get_exp_data(\n",
        "    df=df, class_col='type', feature_col='ethnicity', ratio={'white':0.2, 'black':0.6, 'asian': 0.2}, size=10, randomize=True)\n",
        "print(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJZmhWnis0yh",
        "outputId": "de9eeb88-bd15-442f-e6b5-fca2748063db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for ethnicity: {'black': 0.6, 'white': 0.2, 'asian': 0.2}\n",
            "[] Ratios for type: {'fake': 5, 'real': 5}\n",
            "\n",
            "+----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------+\n",
            "|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                        |\n",
            "|----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------|\n",
            "|  0 | fake   | male   | white       | no           | no       | small  | /content/data/deepfake/594_530/frame121.jpg |\n",
            "|  1 | real   | female | white       | no           |          |        | /content/data/original/240/frame41.jpg      |\n",
            "|  2 | fake   | female | asian       |              |          | big    | /content/data/deepfake/249_280/frame261.jpg |\n",
            "|  3 | real   | female | asian       | no           |          | big    | /content/data/original/758/frame161.jpg     |\n",
            "|  4 | fake   | female | black       | no           |          | big    | /content/data/deepfake/986_994/frame271.jpg |\n",
            "|  5 | fake   | male   | black       | no           | no       | big    | /content/data/deepfake/144_122/frame101.jpg |\n",
            "|  6 | fake   | male   | black       | yes          | no       | big    | /content/data/deepfake/081_087/frame41.jpg  |\n",
            "|  7 | real   | male   | black       | no           | no       | big    | /content/data/original/715/frame231.jpg     |\n",
            "|  8 | real   | female | black       | no           |          | big    | /content/data/original/762/frame61.jpg      |\n",
            "|  9 | real   | female | black       | no           |          | big    | /content/data/original/328/frame241.jpg     |\n",
            "+----+--------+--------+-------------+--------------+----------+--------+---------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    if IMG_RESIZE:\n",
        "      image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "def get_data_for_model(df, class_col, files_col, batch_size):\n",
        "    image_paths = df[files_col].values\n",
        "    labels = df[class_col].values\n",
        "    labels = df[class_col].astype('category').cat.codes.values #classes strs to ints\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    dataset = dataset.map(lambda path, label: (load_image(path), label))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "LNCRWX5js2d7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mobile_net2(num_classes, input_shape, model=None):\n",
        "  if model is None:\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  else:\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  return model, \"mobile net 2\"\n",
        "\n",
        "def create_resnet50(num_classes, input_shape, model=None):\n",
        "  if model is None:\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  else:\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  return model, \"resnet50\"\n",
        "\n",
        "def create_efficientnet_b0(num_classes, input_shape, model=None):\n",
        "  if model is None:\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  else:\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model, \"efficientnet b0\"\n",
        "\n",
        "\n",
        "def create_xception(num_classes, input_shape, model=None):\n",
        "  if model is None:\n",
        "    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  else:\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model, \"xception\"\n"
      ],
      "metadata": {
        "id": "_cfHfqsPvi3O"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder if it doesn't exist\n",
        "if not os.path.exists(RES_PATH):\n",
        "    os.makedirs(RES_PATH)\n",
        "    print(f\"Created folder: {RES_PATH}\")\n",
        "elif REMOVE_RES_CONTENT:\n",
        "    # Remove all files inside the folder\n",
        "    for filename in os.listdir(RES_PATH):\n",
        "        file_path = os.path.join(RES_PATH, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)          # remove file or link\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)      # remove folder and contents\n",
        "        except Exception as e:\n",
        "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
        "    print(f\"Cleared contents of folder: {RES_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYJbzSoMv9Vd",
        "outputId": "54ac94ee-f155-4b2b-fba4-ceeebf9c8b04"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleared contents of folder: /content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_done_reps(model_name, amt_per_rep):\n",
        "  results_path = f'{RES_PATH}res_{model_name.replace(\" \", \"_\")}.csv'\n",
        "  if not os.path.exists(results_path):\n",
        "    return [], None\n",
        "\n",
        "  tmp_df = pd.read_csv(results_path)\n",
        "  dones = []\n",
        "  for r in tmp_df[\"rep\"].unique():\n",
        "    amt = len(tmp_df[tmp_df[\"rep\"]==r])\n",
        "    if amt == amt_per_rep:\n",
        "      dones.append(r)\n",
        "\n",
        "  return dones, tmp_df\n",
        "\n"
      ],
      "metadata": {
        "id": "CQ_JQedB1623"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_tests(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num_head, epochs_num_whole, batch_size):\n",
        "    res = []\n",
        "\n",
        "    _, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "\n",
        "    done_reps, prev_results = get_done_reps(model_name, len(test_metas) * len(train_metas))\n",
        "\n",
        "    for r in range(reps):\n",
        "        if r in done_reps:\n",
        "          res.extend(prev_results[prev_results['rep']==r].values.tolist())\n",
        "          print(f\"Rep {r} already done for {model_name}. Skipping...\")\n",
        "          continue\n",
        "\n",
        "        np.random.seed(SEED + r)\n",
        "        tf.random.set_seed(SEED + r)\n",
        "\n",
        "        for train_meta in train_metas:\n",
        "            train = get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=train_meta['ratio'], size=train_meta['size'])\n",
        "            train = train.sample(frac=1, random_state=SEED+r).reset_index(drop=True)\n",
        "\n",
        "            tests = [\n",
        "                get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=tm['ratio'], size=tm['size'], exclude_column=exclude_column, exclude_df=train) for tm in test_metas\n",
        "            ]\n",
        "\n",
        "            train_dataset = get_data_for_model(train, class_col=class_col, files_col=files_col, batch_size=batch_size)\n",
        "            test_datasets = [\n",
        "                get_data_for_model(test, class_col=class_col, files_col=files_col, batch_size=batch_size) for test in tests\n",
        "            ]\n",
        "\n",
        "            train_ratio = '/'.join([f\"{k}:{v}\" for k, v in train_meta['ratio'].items()])\n",
        "            train_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in train[feature_split_col].value_counts(normalize=True).to_dict().items()])\n",
        "            train_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', train_ratio)\n",
        "\n",
        "            print(\"FITTING HEAD\")\n",
        "            model, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "            model.fit(train_dataset, epochs=epochs_num_head)\n",
        "\n",
        "            print(\"FITTING WHOLE\")\n",
        "            model, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3), model=model)\n",
        "            model.fit(train_dataset, epochs=epochs_num_whole)\n",
        "\n",
        "            for test_dataset, test_meta, test_df in zip(test_datasets, test_metas, tests):\n",
        "                predictions = model.predict(test_dataset)\n",
        "                y_true = test_df[class_col].astype('category').cat.codes.values\n",
        "                y_pred = np.argmax(predictions, axis=1)\n",
        "                acc = accuracy_score(y_true, y_pred)\n",
        "                f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "                eo_diff = equalized_odds_difference(y_true, y_pred, sensitive_features=test_df[feature_split_col])\n",
        "\n",
        "                test_ratio = '/'.join([f\"{k}:{v}\" for k, v in test_meta['ratio'].items()])\n",
        "                test_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in test_df[feature_split_col].value_counts(normalize=True).to_dict().items()])\n",
        "                test_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', test_ratio)\n",
        "\n",
        "                res.append([\n",
        "                    r,\n",
        "                    model_name,\n",
        "                    feature_split_col,\n",
        "                    train_meta['size'],\n",
        "                    train_ratio,\n",
        "                    test_meta['size'],\n",
        "                    test_ratio,\n",
        "                    acc,\n",
        "                    f1,\n",
        "                    eo_diff,\n",
        "                    train_ratio_rel,\n",
        "                    test_ratio_rel,\n",
        "                    train_ratio_sim,\n",
        "                    test_ratio_sim\n",
        "                ])\n",
        "\n",
        "                print(f\"Rep: {r:2} | Model: {model_name} | Feature Split: {feature_split_col} | Ratio: {test_ratio} | Acc: {acc:.2f}\")\n",
        "\n",
        "                res_df = pd.DataFrame(res, columns=[\n",
        "                    'rep', 'model_name', 'feature_split_col',\n",
        "                    'train_size', 'train_ratio_detail', 'test_size', 'test_ratio_detail',\n",
        "                    'accuracy', 'f1_score', 'eo_diff', 'train_ratio_rel', 'test_ratio_rel', \"train_ratio\", \"test_ratio\"\n",
        "                ])\n",
        "\n",
        "                res_df.to_csv(f'{RES_PATH}res_{model_name.replace(\" \", \"_\")}.csv', index=False)\n",
        "    print(f\"Done for {model_name}.\")\n"
      ],
      "metadata": {
        "id": "ik6Z-AUis6G7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_tests(df=df,\n",
        "              train_metas=[\n",
        "                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 5000},\n",
        "                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 5000},\n",
        "                  ],\n",
        "              test_metas=[\n",
        "                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 500},\n",
        "                  {'ratio': {'male':0.3, 'female':0.7}, 'size': 500},\n",
        "                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 500},\n",
        "                  {'ratio': {'male':0.7, 'female':0.3}, 'size': 500},\n",
        "                  {'ratio': {'male':0.9, 'female':0.1}, 'size': 500},\n",
        "              ],\n",
        "              reps=10,\n",
        "              class_col='type',\n",
        "              feature_split_col='sex',\n",
        "              exclude_column='path',\n",
        "              files_col='path',\n",
        "              get_model=create_xception,\n",
        "              epochs_num_head=8,\n",
        "              epochs_num_whole=4,\n",
        "              batch_size=64\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yM2K_awwwv2m",
        "outputId": "e51f9e6a-4fd1-4f2c-acaa-b6806a5a52cd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n",
            "[] Ratios for type: {'fake': 5000, 'real': 5000}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'male': 0.5, 'female': 0.5}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'male': 0.9, 'female': 0.1}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.5055 - loss: 0.7183\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 135ms/step - accuracy: 0.5299 - loss: 0.6900\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 133ms/step - accuracy: 0.5480 - loss: 0.6814\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 136ms/step - accuracy: 0.5751 - loss: 0.6710\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 136ms/step - accuracy: 0.6022 - loss: 0.6585\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 530ms/step - accuracy: 0.5736 - loss: 0.6700\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 465ms/step - accuracy: 0.7698 - loss: 0.4784\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 467ms/step - accuracy: 0.8708 - loss: 0.3069\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 467ms/step - accuracy: 0.9291 - loss: 0.1847\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 471ms/step - accuracy: 0.9664 - loss: 0.1056\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step\n",
            "Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.1/female:0.9 | Acc: 0.89\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step\n",
            "Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.81\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step\n",
            "Rep:  0 | Model: xception | Feature Split: sex | Ratio: male:0.9/female:0.1 | Acc: 0.75\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n",
            "[] Ratios for type: {'fake': 5000, 'real': 5000}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'male': 0.5, 'female': 0.5}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Feature 'None' not found in ratios. Skipping.\n",
            "[] Ratios for sex: {'male': 0.9, 'female': 0.1}\n",
            "[] Ratios for type: {'fake': 500, 'real': 500}\n",
            "\n",
            "Epoch 1/5\n",
            "\u001b[1m179/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.5242 - loss: 0.7169"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-39-1349814394.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m perform_tests(df=df,\n\u001b[0m\u001b[1;32m      2\u001b[0m               train_metas=[\n\u001b[1;32m      3\u001b[0m                   \u001b[0;34m{\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'male'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'female'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   ],\n\u001b[1;32m      5\u001b[0m               test_metas=[\n",
            "\u001b[0;32m/tmp/ipython-input-37-3186714410.py\u001b[0m in \u001b[0;36mperform_tests\u001b[0;34m(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num_head, epochs_num_whole, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_num_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summarise_res(model_name:str):\n",
        "  path = RES_PATH + f'res_{model_name}.csv'\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    print(f\"File {path} does not exists!\")\n",
        "    return\n",
        "\n",
        "  res = pd.read_csv(path)\n",
        "  gr = res.groupby(['train_ratio', 'test_ratio']).agg(\n",
        "      # Model=('model_name', 'first'),\n",
        "      TrainRatio=('train_ratio', 'first'),\n",
        "      TestRatio=('test_ratio', 'first'),\n",
        "      Accuracy= ('accuracy', 'mean'),\n",
        "      AccuracySTD= ('accuracy', 'std'),\n",
        "      F1=('f1_score', 'mean'),\n",
        "      F1STD=('f1_score', 'std'),\n",
        "      EODiff=('eo_diff', 'mean'),\n",
        "      EODiffSTD=('eo_diff', 'std'),\n",
        "  ).reset_index(drop=True)\n",
        "\n",
        "  gr = gr.round(3).sort_values(by=['TrainRatio', 'TestRatio'], ascending=False)\n",
        "\n",
        "  print(\"MODEL: \" + model_name)\n",
        "  print(tb.tabulate(gr, headers='keys', tablefmt='psql'))\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "print_summarise_res('resnet50')\n",
        "print_summarise_res('efficientnet_b0')\n",
        "print_summarise_res('xception')"
      ],
      "metadata": {
        "id": "ivm4W_DLs7jK",
        "outputId": "350e2831-68b5-4934-d285-1d71be381fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/res_resnet50.csv does not exists!\n",
            "File /content/drive/MyDrive/Studia/MAGISTER/PracaMagisterska/res/res_efficientnet_b0.csv does not exists!\n",
            "MODEL: xception\n",
            "+----+--------------+-------------+------------+---------------+-------+---------+----------+-------------+\n",
            "|    | TrainRatio   | TestRatio   |   Accuracy |   AccuracySTD |    F1 |   F1STD |   EODiff |   EODiffSTD |\n",
            "|----+--------------+-------------+------------+---------------+-------+---------+----------+-------------|\n",
            "|  2 | 1/9          | 9/1         |      0.747 |           nan | 0.746 |     nan |    0.178 |         nan |\n",
            "|  1 | 1/9          | 5/5         |      0.814 |           nan | 0.814 |     nan |    0.188 |         nan |\n",
            "|  0 | 1/9          | 1/9         |      0.888 |           nan | 0.888 |     nan |    0.182 |         nan |\n",
            "+----+--------------+-------------+------------+---------------+-------+---------+----------+-------------+\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}