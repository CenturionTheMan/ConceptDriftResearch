{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNmMsy80ByKTqTKo1AGnh2X","include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":12504781,"sourceType":"datasetVersion","datasetId":7892222}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"REMOVE_RES_CONTENT = True\n# IMG_SIZE=299\nIMG_SIZE=224\nIMG_RESIZE = False\nSEED = 42\nRES_PATH = '/kaggle/working/res/'\nDATASET_PATH = '/kaggle/input/deepfakedataset/data/'\nWORKID_DIR_PATH='/kaggle/working/'","metadata":{"id":"jnW2ICuewM0-","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:22:33.495142Z","iopub.execute_input":"2025-07-18T06:22:33.495458Z","iopub.status.idle":"2025-07-18T06:22:33.500198Z","shell.execute_reply.started":"2025-07-18T06:22:33.495432Z","shell.execute_reply":"2025-07-18T06:22:33.499267Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"!pip install -q fairlearn tabulate\nimport zipfile\nimport pandas as pd\nimport numpy as np\nimport tabulate as tb\nfrom typing import Dict\nimport tensorflow as tf\nimport re\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\nfrom tensorflow.keras.applications import Xception, EfficientNetB0, ResNet50\nimport os\nimport shutil\n\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n\ndevice_name = tf.test.gpu_device_name()\nif device_name:\n    print(f\"GPU available: {device_name}\")\nelse:\n    print(\"No GPU available!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPKtaDEKrVlM","outputId":"f35d774d-1a32-46a0-fbb9-1b5dd41d79ad","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:17:50.892054Z","iopub.execute_input":"2025-07-18T06:17:50.892345Z","iopub.status.idle":"2025-07-18T06:17:55.192524Z","shell.execute_reply.started":"2025-07-18T06:17:50.892323Z","shell.execute_reply":"2025-07-18T06:17:55.191580Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hNo GPU available!\n","output_type":"stream"},{"name":"stderr","text":"2025-07-18 06:17:55.188529: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"file_path = DATASET_PATH + 'metadata.csv'\ndf_tmp = pd.read_csv(file_path, sep=',')\ndf_tmp['path'] = DATASET_PATH + df_tmp['path']\n\ndf_tmp = df_tmp[df_tmp['deepfake'] != 0]\n\ndf_tmp['ethnicity'] = df_tmp.apply(\n    lambda row: 'white' if row['white'] == 1 else ('black' if row['black'] == 1 else (\n        'asian' if row['asian'] == 1 else None)), axis=1)\n\ndf = df_tmp[['deepfake', 'male', 'ethnicity', 'eyeglasses', 'heavy_makeup', 'big_lips', 'path']]\n\ndf = df.rename(columns={'deepfake': 'type', 'male': 'sex', 'heavy_makeup': 'makeup', 'big_lips': 'lips',})\n\ndf['type'] = df['type'].replace({1: 'fake', -1: 'real'})\ndf['sex'] = df['sex'].replace({-1: 'female', 0: None, 1: 'male'})\ndf['makeup'] = df['makeup'].replace({-1: 'no', 0: None, 1: 'yes'})\ndf['lips'] = df['lips'].replace({-1: 'small', 0: None, 1: 'big'})\ndf['eyeglasses'] = df['eyeglasses'].replace({-1: 'no', 0: None, 1: 'yes'})\n\n\nprint(tb.tabulate(df.head(), headers='keys', tablefmt='psql'))\nprint(f\"Dataset size: {len(df)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQHjq4DXrY3h","outputId":"ee466649-50e5-43a4-c318-b6aedc03dc0d","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:07.787045Z","iopub.execute_input":"2025-07-18T06:24:07.787354Z","iopub.status.idle":"2025-07-18T06:24:08.717606Z","shell.execute_reply.started":"2025-07-18T06:24:07.787332Z","shell.execute_reply":"2025-07-18T06:24:08.716824Z"}},"outputs":[{"name":"stdout","text":"+----+--------+--------+-------------+--------------+----------+--------+--------------------------------------------------------------+\n|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                                         |\n|----+--------+--------+-------------+--------------+----------+--------+--------------------------------------------------------------|\n|  0 | real   | male   |             | yes          | no       | big    | /kaggle/input/deepfakedataset/data/original/805/frame271.jpg |\n|  1 | real   | female | white       | no           |          | big    | /kaggle/input/deepfakedataset/data/original/083/frame191.jpg |\n|  2 | real   | male   | white       | no           | no       | small  | /kaggle/input/deepfakedataset/data/original/878/frame111.jpg |\n|  3 | real   | female | white       | no           |          |        | /kaggle/input/deepfakedataset/data/original/158/frame201.jpg |\n|  4 | real   | female | white       | no           |          |        | /kaggle/input/deepfakedataset/data/original/606/frame71.jpg  |\n+----+--------+--------+-------------+--------------+----------+--------+--------------------------------------------------------------+\nDataset size: 59552\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def get_balanced_subset(\n    df, class_col, feature_col, feature_value,\n    samples_per_class, randomize=True, reset_index=False\n):\n    \"\"\"\n    Select a balanced subset of the data for a given feature value, with equal number of samples per class.\n\n    Args:\n        df: DataFrame\n        class_col: column name of class labels\n        feature_col: column name of feature\n        feature_value: specific feature value to filter\n        samples_per_class: number of samples per class\n        randomize: whether to shuffle within class before selecting\n        reset_index: whether to reset index of returned DataFrame\n        seed: random seed for reproducibility\n\n    Returns:\n        Balanced DataFrame subset\n    \"\"\"\n    tmp = df[df[feature_col] == feature_value]\n\n    counts = tmp[class_col].value_counts()\n    for cl, count in counts.items():\n        if count < samples_per_class:\n            raise ValueError(f\"Not enough samples for class '{cl}' in feature '{feature_value}'. \"\n                             f\"Required: {samples_per_class}, Available: {count}\")\n\n    tmp = pd.concat([\n        (g.sample(frac=1, random_state=SEED).head(samples_per_class) if randomize else g.head(samples_per_class))\n        for _, g in tmp.groupby(class_col)\n    ])\n\n    if reset_index:\n        tmp = tmp.reset_index(drop=True)\n\n    return tmp\n\ntmp_test = get_balanced_subset(\n    df=df, class_col='type', feature_col='sex', feature_value='male',\n    samples_per_class=2, randomize=True, reset_index=True)\nprint(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqJXku-tsxK7","outputId":"03c62d12-4bff-4e41-cd9b-7d694cc52732","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:21.026919Z","iopub.execute_input":"2025-07-18T06:24:21.027421Z","iopub.status.idle":"2025-07-18T06:24:21.066959Z","shell.execute_reply.started":"2025-07-18T06:24:21.027398Z","shell.execute_reply":"2025-07-18T06:24:21.066059Z"}},"outputs":[{"name":"stdout","text":"+----+--------+-------+-------------+--------------+----------+--------+------------------------------------------------------------------+\n|    | type   | sex   | ethnicity   | eyeglasses   | makeup   | lips   | path                                                             |\n|----+--------+-------+-------------+--------------+----------+--------+------------------------------------------------------------------|\n|  0 | fake   | male  | white       | no           | no       | small  | /kaggle/input/deepfakedataset/data/deepfake/374_407/frame41.jpg  |\n|  1 | fake   | male  | white       | no           | no       | small  | /kaggle/input/deepfakedataset/data/deepfake/015_919/frame281.jpg |\n|  2 | real   | male  |             | no           | no       | big    | /kaggle/input/deepfakedataset/data/original/995/frame11.jpg      |\n|  3 | real   | male  | white       | no           | no       |        | /kaggle/input/deepfakedataset/data/original/579/frame201.jpg     |\n+----+--------+-------+-------------+--------------+----------+--------+------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def get_exp_data(df, class_col, feature_col, ratio : Dict, size, randomize=True, exclude_column=None, exclude_df=None, max_diff=0.05):\n    '''\n    Get a balanced subset of the data based on specified ratios for features.\n    Args:\n        df: DataFrame containing the data\n        class_col: column name for class labels\n        feature_col: column name for features\n        ratio: dictionary with feature values as keys and their ratios as values\n        size: total number of samples to return\n        randomize: whether to shuffle the DataFrame before processing\n        exclude_column: column name to exclude from the DataFrame\n        exclude_df: DataFrame containing values to exclude based on exclude_column\n    '''\n    if randomize:\n        df_rnd = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n    else:\n        df_rnd = df.copy()\n\n    if exclude_column is not None and exclude_df is not None:\n        if exclude_column not in df_rnd.columns:\n            raise ValueError(f\"Column '{exclude_column}' not found in DataFrame.\")\n        if exclude_column not in exclude_df.columns:\n            raise ValueError(f\"Column '{exclude_column}' not found in exclude DataFrame.\")\n        df_rnd = df_rnd[~df_rnd[exclude_column].isin(exclude_df[exclude_column])]\n\n    uniq_classes = df_rnd[class_col].unique()\n    uniq_features = df_rnd[feature_col].unique()\n\n    def get_exp_data_inner(tmp_df, size):\n        df_tmp = None\n        for uf in uniq_features:\n            if ratio.get(uf) is None:\n                print(f\"Feature '{uf}' not found in ratios. Skipping.\")\n                continue\n            c_amt = int(size * ratio[uf] / len(uniq_classes))\n            # if c_amt <= 0:\n            #     raise ValueError(f\"Calculated samples per class ({c_amt}) is less than or equal to zero for feature '{uf}' with ratio {ratio}.\")\n            tmp = get_balanced_subset(df=tmp_df, class_col=class_col, feature_col=feature_col, feature_value=uf,\n                                        samples_per_class=c_amt, randomize=False)\n            if df_tmp is None:\n                df_tmp = tmp\n            else:\n                df_tmp = pd.concat([df_tmp, tmp])\n        return df_tmp\n\n    df_res = get_exp_data_inner(df_rnd, size)\n\n    if len(df_res) < size:\n        print(f\"Samples for ({len(df_res)}) are less than requested ({size}).\")\n\n    ratios_fet = df_res[feature_col].value_counts(normalize=True).to_dict()\n    ratios_cls = df_res[class_col].value_counts(normalize=False).to_dict()\n    print(f\"[] Ratios for {feature_col}: {ratios_fet}\")\n    print(f\"[] Ratios for {class_col}: {ratios_cls}\")\n\n    for k in ratio:\n        if ratios_fet.get(k) is None:\n            if ratio[k] > 0.0:\n                raise ValueError(f\"Feature '{k}' not found in DataFrame after sampling (try increase 'size' parameter).\")\n        elif abs(ratios_fet[k] - ratio[k]) > max_diff:\n            raise ValueError(f\"Feature '{k}' ratio {ratios_fet[k]} differs from requested {ratio[k]} by more than {max_diff}.\")\n\n    print()\n\n    df_res = df_res.reset_index(drop=True)\n\n    return df_res\n\ntmp_test = get_exp_data(\n    df=df, class_col='type', feature_col='ethnicity', ratio={'white':0.2, 'black':0.6, 'asian': 0.2}, size=10, randomize=True)\nprint(tb.tabulate(tmp_test, headers='keys', tablefmt='psql'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJZmhWnis0yh","outputId":"555bdf23-ce59-42e2-da9c-dffb8e307822","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:24.904913Z","iopub.execute_input":"2025-07-18T06:24:24.905443Z","iopub.status.idle":"2025-07-18T06:24:24.976655Z","shell.execute_reply.started":"2025-07-18T06:24:24.905416Z","shell.execute_reply":"2025-07-18T06:24:24.975833Z"}},"outputs":[{"name":"stdout","text":"Feature 'None' not found in ratios. Skipping.\n[] Ratios for ethnicity: {'black': 0.6, 'white': 0.2, 'asian': 0.2}\n[] Ratios for type: {'fake': 5, 'real': 5}\n\n+----+--------+--------+-------------+--------------+----------+--------+------------------------------------------------------------------+\n|    | type   | sex    | ethnicity   | eyeglasses   | makeup   | lips   | path                                                             |\n|----+--------+--------+-------------+--------------+----------+--------+------------------------------------------------------------------|\n|  0 | fake   | male   | white       | no           | no       | small  | /kaggle/input/deepfakedataset/data/deepfake/594_530/frame121.jpg |\n|  1 | real   | female | white       | no           |          |        | /kaggle/input/deepfakedataset/data/original/240/frame41.jpg      |\n|  2 | fake   | female | asian       |              |          | big    | /kaggle/input/deepfakedataset/data/deepfake/249_280/frame261.jpg |\n|  3 | real   | female | asian       | no           |          | big    | /kaggle/input/deepfakedataset/data/original/758/frame161.jpg     |\n|  4 | fake   | female | black       | no           |          | big    | /kaggle/input/deepfakedataset/data/deepfake/986_994/frame271.jpg |\n|  5 | fake   | male   | black       | no           | no       | big    | /kaggle/input/deepfakedataset/data/deepfake/144_122/frame101.jpg |\n|  6 | fake   | male   | black       | yes          | no       | big    | /kaggle/input/deepfakedataset/data/deepfake/081_087/frame41.jpg  |\n|  7 | real   | male   | black       | no           | no       | big    | /kaggle/input/deepfakedataset/data/original/715/frame231.jpg     |\n|  8 | real   | female | black       | no           |          | big    | /kaggle/input/deepfakedataset/data/original/762/frame61.jpg      |\n|  9 | real   | female | black       | no           |          | big    | /kaggle/input/deepfakedataset/data/original/328/frame241.jpg     |\n+----+--------+--------+-------------+--------------+----------+--------+------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def load_image(file_path):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    if IMG_RESIZE:\n      image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\ndef get_data_for_model(df, class_col, files_col, batch_size):\n    image_paths = df[files_col].values\n    labels = df[class_col].values\n    labels = df[class_col].astype('category').cat.codes.values #classes strs to ints\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n    dataset = dataset.map(lambda path, label: (load_image(path), label))\n    dataset = dataset.batch(batch_size)\n    return dataset","metadata":{"id":"LNCRWX5js2d7","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:29.911937Z","iopub.execute_input":"2025-07-18T06:24:29.912685Z","iopub.status.idle":"2025-07-18T06:24:29.918280Z","shell.execute_reply.started":"2025-07-18T06:24:29.912660Z","shell.execute_reply":"2025-07-18T06:24:29.917535Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def create_mobile_net2(num_classes, input_shape, model=None):\n  if model is None:\n    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n  else:\n    for layer in model.layers:\n        layer.trainable = True\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n  return model, \"mobile net 2\"\n\ndef create_resnet50(num_classes, input_shape, model=None):\n  if model is None:\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n  else:\n    for layer in model.layers:\n      layer.trainable = True\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n  return model, \"resnet50\"\n\ndef create_efficientnet_b0(num_classes, input_shape, model=None):\n  if model is None:\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n  else:\n    for layer in model.layers:\n      layer.trainable = True\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n  return model, \"efficientnet b0\"\n\n\ndef create_xception(num_classes, input_shape, model=None):\n  if model is None:\n    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128, activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n  else:\n    for layer in model.layers:\n        layer.trainable = True\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n  return model, \"xception\"\n","metadata":{"id":"_cfHfqsPvi3O","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:31.972947Z","iopub.execute_input":"2025-07-18T06:24:31.973243Z","iopub.status.idle":"2025-07-18T06:24:31.986224Z","shell.execute_reply.started":"2025-07-18T06:24:31.973221Z","shell.execute_reply":"2025-07-18T06:24:31.985359Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Create folder if it doesn't exist\nif not os.path.exists(RES_PATH):\n    os.makedirs(RES_PATH)\n    print(f\"Created folder: {RES_PATH}\")\nelif REMOVE_RES_CONTENT:\n    # Remove all files inside the folder\n    for filename in os.listdir(RES_PATH):\n        file_path = os.path.join(RES_PATH, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)          # remove file or link\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)      # remove folder and contents\n        except Exception as e:\n            print(f'Failed to delete {file_path}. Reason: {e}')\n    print(f\"Cleared contents of folder: {RES_PATH}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYJbzSoMv9Vd","outputId":"07789495-ad79-42f3-eacb-3cc9507b3425","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:45.535456Z","iopub.execute_input":"2025-07-18T06:24:45.535750Z","iopub.status.idle":"2025-07-18T06:24:45.542465Z","shell.execute_reply.started":"2025-07-18T06:24:45.535727Z","shell.execute_reply":"2025-07-18T06:24:45.541568Z"}},"outputs":[{"name":"stdout","text":"Created folder: /kaggle/working/res/\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def get_done_reps(model_name, feature_name, amt_per_rep):\n  results_path = f'{RES_PATH}res_{feature_name}_{model_name.replace(\" \", \"_\")}.csv'\n  if not os.path.exists(results_path):\n    return [], None\n\n  tmp_df = pd.read_csv(results_path)\n  dones = []\n  for r in tmp_df[\"rep\"].unique():\n    amt = len(tmp_df[tmp_df[\"rep\"]==r])\n    if amt == amt_per_rep:\n      dones.append(r)\n\n  return dones, tmp_df","metadata":{"id":"CQ_JQedB1623","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:26:11.835316Z","iopub.execute_input":"2025-07-18T06:26:11.835994Z","iopub.status.idle":"2025-07-18T06:26:11.840801Z","shell.execute_reply.started":"2025-07-18T06:26:11.835966Z","shell.execute_reply":"2025-07-18T06:26:11.839964Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def perform_tests(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num_head, epochs_num_whole, batch_size):\n    res = []\n\n    _, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3))\n\n    done_reps, prev_results = get_done_reps(model_name, feature_split_col, len(test_metas) * len(train_metas))\n\n    for r in range(reps):\n        if r in done_reps:\n          res.extend(prev_results[prev_results['rep']==r].values.tolist())\n          print(f\"Rep {r} already done for {model_name}. Skipping...\")\n          continue\n\n        np.random.seed(SEED + r)\n        tf.random.set_seed(SEED + r)\n\n        for train_meta in train_metas:\n            train = get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=train_meta['ratio'], size=train_meta['size'])\n            train = train.sample(frac=1, random_state=SEED+r).reset_index(drop=True)\n\n            tests = [\n                get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=tm['ratio'], size=tm['size'], exclude_column=exclude_column, exclude_df=train) for tm in test_metas\n            ]\n\n            train_dataset = get_data_for_model(train, class_col=class_col, files_col=files_col, batch_size=batch_size)\n            test_datasets = [\n                get_data_for_model(test, class_col=class_col, files_col=files_col, batch_size=batch_size) for test in tests\n            ]\n\n            train_ratio = '/'.join([f\"{k}:{v}\" for k, v in train_meta['ratio'].items()])\n            train_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in train[feature_split_col].value_counts(normalize=True).to_dict().items()])\n            train_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', train_ratio)\n\n            print(\"FITTING HEAD\")\n            model, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3))\n            model.fit(train_dataset, epochs=epochs_num_head)\n\n            print(\"FITTING WHOLE\")\n            model, model_name = get_model(num_classes=len(df[class_col].unique()), input_shape=(IMG_SIZE,IMG_SIZE,3), model=model)\n            model.fit(train_dataset, epochs=epochs_num_whole)\n\n            for test_dataset, test_meta, test_df in zip(test_datasets, test_metas, tests):\n                predictions = model.predict(test_dataset)\n                y_true = test_df[class_col].astype('category').cat.codes.values\n                y_pred = np.argmax(predictions, axis=1)\n                acc = accuracy_score(y_true, y_pred)\n                f1 = f1_score(y_true, y_pred, average='weighted')\n                eo_diff = equalized_odds_difference(y_true, y_pred, sensitive_features=test_df[feature_split_col])\n\n                test_ratio = '/'.join([f\"{k}:{v}\" for k, v in test_meta['ratio'].items()])\n                test_ratio_rel = '/'.join([f\"{k}:{v:.4f}\" for k, v in test_df[feature_split_col].value_counts(normalize=True).to_dict().items()])\n                test_ratio_sim = re.sub(r'[a-zA-Z0.:]', '', test_ratio)\n\n                res.append([\n                    r,\n                    model_name,\n                    feature_split_col,\n                    train_meta['size'],\n                    train_ratio,\n                    test_meta['size'],\n                    test_ratio,\n                    acc,\n                    f1,\n                    eo_diff,\n                    train_ratio_rel,\n                    test_ratio_rel,\n                    train_ratio_sim,\n                    test_ratio_sim\n                ])\n\n                print(f\"Rep: {r:2} | Model: {model_name} | Feature Split: {feature_split_col} | Ratio: {test_ratio} | Acc: {acc:.2f}\")\n\n                res_df = pd.DataFrame(res, columns=[\n                    'rep', 'model_name', 'feature_split_col',\n                    'train_size', 'train_ratio_detail', 'test_size', 'test_ratio_detail',\n                    'accuracy', 'f1_score', 'eo_diff', 'train_ratio_rel', 'test_ratio_rel', \"train_ratio\", \"test_ratio\"\n                ])\n\n                res_df.to_csv(f'{RES_PATH}res_{feature_split_col}_{model_name.replace(\" \", \"_\")}.csv', index=False)\n    print(f\"Done for {model_name}.\")\n","metadata":{"id":"ik6Z-AUis6G7","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:26:13.728840Z","iopub.execute_input":"2025-07-18T06:26:13.729145Z","iopub.status.idle":"2025-07-18T06:26:13.743510Z","shell.execute_reply.started":"2025-07-18T06:26:13.729121Z","shell.execute_reply":"2025-07-18T06:26:13.742646Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\nperform_tests(df=df,\n              train_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 5000},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 5000},\n                  ],\n              test_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 500},\n                  {'ratio': {'male':0.3, 'female':0.7}, 'size': 500},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 500},\n                  {'ratio': {'male':0.7, 'female':0.3}, 'size': 500},\n                  {'ratio': {'male':0.9, 'female':0.1}, 'size': 500},\n              ],\n              reps=10,\n              class_col='type',\n              feature_split_col='sex',\n              exclude_column='path',\n              files_col='path',\n              get_model=create_resnet50,\n              epochs_num_head=8,\n              epochs_num_whole=4,\n              batch_size=64\n              )\n\nperform_tests(df=df,\n              train_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 5000},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 5000},\n                  ],\n              test_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 500},\n                  {'ratio': {'male':0.3, 'female':0.7}, 'size': 500},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 500},\n                  {'ratio': {'male':0.7, 'female':0.3}, 'size': 500},\n                  {'ratio': {'male':0.9, 'female':0.1}, 'size': 500},\n              ],\n              reps=10,\n              class_col='type',\n              feature_split_col='sex',\n              exclude_column='path',\n              files_col='path',\n              get_model=create_efficientnet_b0,\n              epochs_num_head=8,\n              epochs_num_whole=4,\n              batch_size=64\n              )\n\nperform_tests(df=df,\n              train_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 5000},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 5000},\n                  ],\n              test_metas=[\n                  {'ratio': {'male':0.1, 'female':0.9}, 'size': 500},\n                  {'ratio': {'male':0.3, 'female':0.7}, 'size': 500},\n                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 500},\n                  {'ratio': {'male':0.7, 'female':0.3}, 'size': 500},\n                  {'ratio': {'male':0.9, 'female':0.1}, 'size': 500},\n              ],\n              reps=10,\n              class_col='type',\n              feature_split_col='sex',\n              exclude_column='path',\n              files_col='path',\n              get_model=create_xception,\n              epochs_num_head=8,\n              epochs_num_whole=4,\n              batch_size=64\n              )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yM2K_awwwv2m","outputId":"65cbb83b-b777-4386-d68f-0cd46a28dc09","trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:26:27.325876Z","iopub.execute_input":"2025-07-18T06:26:27.326414Z","iopub.status.idle":"2025-07-18T06:27:19.493499Z","shell.execute_reply.started":"2025-07-18T06:26:27.326388Z","shell.execute_reply":"2025-07-18T06:27:19.491795Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n[] Ratios for type: {'fake': 2500, 'real': 2500}\n\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'female': 0.9, 'male': 0.1}\n[] Ratios for type: {'fake': 250, 'real': 250}\n\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'female': 0.7, 'male': 0.3}\n[] Ratios for type: {'fake': 250, 'real': 250}\n\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'male': 0.5, 'female': 0.5}\n[] Ratios for type: {'fake': 250, 'real': 250}\n\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'male': 0.7, 'female': 0.3}\n[] Ratios for type: {'fake': 250, 'real': 250}\n\nFeature 'None' not found in ratios. Skipping.\n[] Ratios for sex: {'male': 0.9, 'female': 0.1}\n[] Ratios for type: {'fake': 250, 'real': 250}\n\nFITTING HEAD\nEpoch 1/8\n\u001b[1m 6/79\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:01\u001b[0m 5s/step - accuracy: 0.5638 - loss: 1.2079","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3424469684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m perform_tests(df=df,\n\u001b[0m\u001b[1;32m      2\u001b[0m               train_metas=[\n\u001b[1;32m      3\u001b[0m                   \u001b[0;34m{\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'male'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'female'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;34m{\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'male'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'female'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   ],\n","\u001b[0;32m/tmp/ipykernel_36/3924895921.py\u001b[0m in \u001b[0;36mperform_tests\u001b[0;34m(df, train_metas, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num_head, epochs_num_whole, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FITTING HEAD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_num_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FITTING WHOLE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"def print_summarise_res(model_name:str):\n  path = RES_PATH + f'res_sex_{model_name}.csv'\n\n  if not os.path.exists(path):\n    print(f\"File {path} does not exists!\")\n    return\n\n  res = pd.read_csv(path)\n  gr = res.groupby(['train_ratio', 'test_ratio']).agg(\n      # Model=('model_name', 'first'),\n      TrainRatio=('train_ratio', 'first'),\n      TestRatio=('test_ratio', 'first'),\n      Accuracy= ('accuracy', 'mean'),\n      AccuracySTD= ('accuracy', 'std'),\n      F1=('f1_score', 'mean'),\n      F1STD=('f1_score', 'std'),\n      EODiff=('eo_diff', 'mean'),\n      EODiffSTD=('eo_diff', 'std'),\n  ).reset_index(drop=True)\n\n  gr = gr.round(3).sort_values(by=['TrainRatio', 'TestRatio'], ascending=False)\n\n  print(\"MODEL: \" + model_name)\n  print(tb.tabulate(gr, headers='keys', tablefmt='psql'))\n  print()\n  print()\n\nprint_summarise_res('resnet50')\nprint_summarise_res('efficientnet_b0')\nprint_summarise_res('xception')","metadata":{"id":"ivm4W_DLs7jK"},"outputs":[],"execution_count":null}]}