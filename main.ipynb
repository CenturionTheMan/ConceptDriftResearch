{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d84430f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabulate as tb\n",
    "from typing import Dict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0abeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+----------------------------------------------------+\n",
      "|      | dx    | sex   | file_path                                          |\n",
      "|------+-------+-------+----------------------------------------------------|\n",
      "| 2462 | bcc   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0028155.jpg |\n",
      "| 2982 | nv    | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0031325.jpg |\n",
      "|    0 | bkl   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0027419.jpg |\n",
      "| 9689 | akiec | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0029360.jpg |\n",
      "| 1213 | mel   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0027190.jpg |\n",
      "| 2321 | vasc  | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0031270.jpg |\n",
      "|   64 | nv    | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0024698.jpg |\n",
      "|    1 | bkl   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0025030.jpg |\n",
      "| 9690 | akiec | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0026152.jpg |\n",
      "| 1096 | df    | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0028790.jpg |\n",
      "| 2320 | vasc  | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0031197.jpg |\n",
      "| 2464 | bcc   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0029230.jpg |\n",
      "| 1095 | df    | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0027008.jpg |\n",
      "| 1214 | mel   | male  | Skin Cancer MNIST/HAM10000_images/ISIC_0031023.jpg |\n",
      "+------+-------+-------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# file_path = './DeepFake Annotations/A-FF++.csv'\n",
    "file_path = './data/HAM10000_metadata.csv'\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "df['file_path'] = 'Skin Cancer MNIST/HAM10000_images/' + df['image_id'] + '.jpg'\n",
    "\n",
    "df = df.drop(columns=['image_id', 'lesion_id', 'dx_type', 'age', 'localization'])\n",
    "\n",
    "def get_balanced_subset(df, class_col, feature_col, feature_value, samples_per_class, randomize=True, reset_index=False):\n",
    "    tmp = df[df[feature_col] == feature_value]\n",
    "    \n",
    "    unique_classes = tmp[class_col].unique()\n",
    "    for cl in unique_classes:\n",
    "        amt = len(tmp[tmp[class_col] == cl])\n",
    "        if amt < samples_per_class:\n",
    "            raise ValueError(f\"Not enough samples for class '{cl}' in feature '{feature_value}'. \"\n",
    "                             f\"Required: {samples_per_class}, Available: {len(tmp[tmp[class_col] == cl])}\")\n",
    "   \n",
    "    tmp = tmp.groupby(class_col).head(samples_per_class)\n",
    "    if randomize:\n",
    "        tmp = tmp.sample(len(tmp), random_state=SEED)\n",
    "    if reset_index:\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "    \n",
    "    return tmp    \n",
    "\n",
    "tmp = get_balanced_subset(df=df, class_col='dx', feature_col='sex', feature_value='male', samples_per_class=2)\n",
    "print(tb.tabulate(tmp, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f991920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_data(df, class_col, feature_col, ratio : Dict, size, randomize=True, exclude_column=None, exclude_df=None):\n",
    "    if randomize:\n",
    "        df_rnd = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    else:\n",
    "        df_rnd = df.copy()\n",
    "        \n",
    "    if exclude_column is not None and exclude_df is not None:\n",
    "        if exclude_column not in df_rnd.columns:\n",
    "            raise ValueError(f\"Column '{exclude_column}' not found in DataFrame.\")\n",
    "        if exclude_column not in exclude_df.columns:\n",
    "            raise ValueError(f\"Column '{exclude_column}' not found in exclude DataFrame.\")\n",
    "        df_rnd = df_rnd[~df_rnd[exclude_column].isin(exclude_df[exclude_column])]\n",
    "         \n",
    "\n",
    "        \n",
    "    uniq_classes = df_rnd[class_col].unique()\n",
    "    uniq_features = df_rnd[feature_col].unique()\n",
    "    \n",
    "    def get_exp_data_inner(tmp_df, size):\n",
    "        df_tmp = None\n",
    "        for uf in uniq_features:\n",
    "            if ratio.get(uf) is None:\n",
    "                print(f\"Feature '{uf}' not found in ratios. Skipping.\")\n",
    "                continue            \n",
    "            c_amt = int(size * ratio[uf] / len(uniq_classes))\n",
    "            if c_amt <= 0:\n",
    "                raise ValueError(f\"Calculated samples per class ({c_amt}) is less than or equal to zero for feature '{uf}' with ratio {ratio}.\")\n",
    "            tmp = get_balanced_subset(df=tmp_df, class_col=class_col, feature_col=feature_col, feature_value=uf, \n",
    "                                        samples_per_class=c_amt, randomize=False)\n",
    "            if df_tmp is None:\n",
    "                df_tmp = tmp\n",
    "            else:\n",
    "                df_tmp = pd.concat([df_tmp, tmp])\n",
    "        return df_tmp\n",
    "            \n",
    "    df_res = get_exp_data_inner(df_rnd, size)\n",
    "    \n",
    "    if len(df_res) < size:\n",
    "        print(f\"Samples for ({len(df_res)}) are less than requested ({size}).\")\n",
    "    \n",
    "    #PRINT RATIOS\n",
    "    ratios = df_res[feature_col].value_counts(normalize=True).to_dict()\n",
    "    print(f\"Ratios for features: {ratios}\")\n",
    "    \n",
    "    df_res = df_res.reset_index(drop=True)\n",
    "    \n",
    "    return df_res      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f4b1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, target_size=(224, 224)):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def get_data_for_model(df, class_col, files_col):\n",
    "    image_paths = df[files_col].values\n",
    "    labels = df[class_col].values\n",
    "    labels = df[class_col].astype('category').cat.codes.values #classes strs to ints\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(lambda path, label: (load_image(path), label))\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset\n",
    "    \n",
    "def create_simple_model(num_classes, input_shape=(224, 224, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model, \"CNV\"\n",
    "\n",
    "\n",
    "def create_mobile_net2(num_classes, input_shape=(224, 224, 3)):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model, \"mobile net 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "737ae7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_50_50 = get_exp_data(df, class_col='dx', feature_col='sex', ratio={'male':0.5, 'female': 0.5}, size=500)\n",
    "# # print(tb.tabulate(train_50_50, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# test_50_50 = get_exp_data(df, class_col='dx', feature_col='sex', ratio={'male':0.5, 'female': 0.5}, size=100, exclude_column='file_path', exclude_df=train_50_50)\n",
    "# # test_40_60 = get_exp_data(df, class_col='dx', feature_col='sex', ratio={'male':0.4, 'female': 0.6}, size=100, exclude_column='file_path', exclude_df=train_50_50)\n",
    "# # test_30_70 = get_exp_data(df, class_col='dx', feature_col='sex', ratio={'male':0.3, 'female': 0.7}, size=100, exclude_column='file_path', exclude_df=train_50_50)\n",
    "\n",
    "# num_classes = len(df['dx'].unique())\n",
    "# model = create_simple_model(num_classes=num_classes)\n",
    "\n",
    "# # Train the model\n",
    "# train_dataset = get_data_for_model(train_50_50, class_col='dx', files_col='file_path')\n",
    "# model.fit(train_dataset, epochs=20)\n",
    "\n",
    "# # Make test predictions\n",
    "# test_dataset = get_data_for_model(test_50_50, class_col='dx', files_col='file_path')\n",
    "# predictions = model.predict(test_dataset)\n",
    "\n",
    "# # calcu accuracy, F1\n",
    "# y_true = test_50_50['dx'].astype('category').cat.codes.values\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "# f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565ac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (497) are less than requested (500).\n",
      "Ratios for features: {'male': 0.704225352112676, 'female': 0.29577464788732394}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'male': 0.7142857142857143, 'female': 0.2857142857142857}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'male': 0.6153846153846154, 'female': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.5, 'male': 0.5}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'female': 0.6153846153846154, 'male': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.7142857142857143, 'male': 0.2857142857142857}\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 508ms/step - accuracy: 0.2060 - loss: 2.5943\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 533ms/step - accuracy: 0.1592 - loss: 2.3987\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 520ms/step - accuracy: 0.4172 - loss: 1.6074\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 503ms/step - accuracy: 0.3758 - loss: 1.5642\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 501ms/step - accuracy: 0.4886 - loss: 1.3961\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 506ms/step - accuracy: 0.5589 - loss: 1.2830\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 520ms/step - accuracy: 0.6422 - loss: 1.1401\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - accuracy: 0.6653 - loss: 1.0592\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 500ms/step - accuracy: 0.7066 - loss: 0.9488\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 519ms/step - accuracy: 0.7628 - loss: 0.8503\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 713ms/step\n",
      "Rep:  0 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.7/female:0.3 | Acc: 0.41\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step\n",
      "Rep:  0 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.6/female:0.4 | Acc: 0.43\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 346ms/step\n",
      "Rep:  0 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.43\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 484ms/step\n",
      "Rep:  0 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.4/female:0.6 | Acc: 0.45\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step\n",
      "Rep:  0 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.3/female:0.7 | Acc: 0.46\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (497) are less than requested (500).\n",
      "Ratios for features: {'male': 0.704225352112676, 'female': 0.29577464788732394}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'male': 0.7142857142857143, 'female': 0.2857142857142857}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'male': 0.6153846153846154, 'female': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.5, 'male': 0.5}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'female': 0.6153846153846154, 'male': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.7142857142857143, 'male': 0.2857142857142857}\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 500ms/step - accuracy: 0.2324 - loss: 2.3124\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 499ms/step - accuracy: 0.2246 - loss: 2.3419\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 510ms/step - accuracy: 0.3982 - loss: 1.6062\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 557ms/step - accuracy: 0.4621 - loss: 1.4372\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 579ms/step - accuracy: 0.5353 - loss: 1.2913\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587ms/step - accuracy: 0.5586 - loss: 1.2082\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 648ms/step - accuracy: 0.6192 - loss: 1.0707\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 574ms/step - accuracy: 0.6601 - loss: 0.9666\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 572ms/step - accuracy: 0.7426 - loss: 0.8723\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534ms/step - accuracy: 0.8026 - loss: 0.7842\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step\n",
      "Rep:  1 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.7/female:0.3 | Acc: 0.45\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step\n",
      "Rep:  1 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.6/female:0.4 | Acc: 0.48\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step\n",
      "Rep:  1 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.49\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 509ms/step\n",
      "Rep:  1 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.4/female:0.6 | Acc: 0.51\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step\n",
      "Rep:  1 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.3/female:0.7 | Acc: 0.50\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (497) are less than requested (500).\n",
      "Ratios for features: {'male': 0.704225352112676, 'female': 0.29577464788732394}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'male': 0.7142857142857143, 'female': 0.2857142857142857}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'male': 0.6153846153846154, 'female': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.5, 'male': 0.5}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'female': 0.6153846153846154, 'male': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.7142857142857143, 'male': 0.2857142857142857}\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 539ms/step - accuracy: 0.1878 - loss: 2.3050\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 586ms/step - accuracy: 0.1532 - loss: 2.6568\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593ms/step - accuracy: 0.4063 - loss: 1.6253\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 604ms/step - accuracy: 0.4714 - loss: 1.4898\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 580ms/step - accuracy: 0.4958 - loss: 1.4111\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 508ms/step - accuracy: 0.5623 - loss: 1.2764\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 515ms/step - accuracy: 0.6099 - loss: 1.1487\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 508ms/step - accuracy: 0.6399 - loss: 1.0623\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 503ms/step - accuracy: 0.6741 - loss: 0.9662\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 513ms/step - accuracy: 0.7392 - loss: 0.8897\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 759ms/step\n",
      "Rep:  2 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.7/female:0.3 | Acc: 0.42\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 496ms/step\n",
      "Rep:  2 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.6/female:0.4 | Acc: 0.46\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 345ms/step\n",
      "Rep:  2 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.47\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 496ms/step\n",
      "Rep:  2 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.4/female:0.6 | Acc: 0.47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step\n",
      "Rep:  2 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.3/female:0.7 | Acc: 0.48\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (497) are less than requested (500).\n",
      "Ratios for features: {'male': 0.704225352112676, 'female': 0.29577464788732394}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'male': 0.7142857142857143, 'female': 0.2857142857142857}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'male': 0.6153846153846154, 'female': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.5, 'male': 0.5}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'female': 0.6153846153846154, 'male': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.7142857142857143, 'male': 0.2857142857142857}\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.2150 - loss: 2.4276\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.2061 - loss: 2.2464\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 472ms/step - accuracy: 0.3358 - loss: 1.6195\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.4219 - loss: 1.4546\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.5386 - loss: 1.3142\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.5572 - loss: 1.2012\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.6588 - loss: 1.0355\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 481ms/step - accuracy: 0.6763 - loss: 0.9617\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 518ms/step - accuracy: 0.7320 - loss: 0.8564\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.7967 - loss: 0.7645\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 587ms/step\n",
      "Rep:  3 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.7/female:0.3 | Acc: 0.46\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step\n",
      "Rep:  3 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.6/female:0.4 | Acc: 0.47\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step\n",
      "Rep:  3 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.48\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step\n",
      "Rep:  3 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.4/female:0.6 | Acc: 0.48\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step\n",
      "Rep:  3 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.3/female:0.7 | Acc: 0.48\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (497) are less than requested (500).\n",
      "Ratios for features: {'male': 0.704225352112676, 'female': 0.29577464788732394}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'male': 0.7142857142857143, 'female': 0.2857142857142857}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'male': 0.6153846153846154, 'female': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.5, 'male': 0.5}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (91) are less than requested (100).\n",
      "Ratios for features: {'female': 0.6153846153846154, 'male': 0.38461538461538464}\n",
      "Feature 'unknown' not found in ratios. Skipping.\n",
      "Samples for (98) are less than requested (100).\n",
      "Ratios for features: {'female': 0.7142857142857143, 'male': 0.2857142857142857}\n",
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.1933 - loss: 2.4015\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.2089 - loss: 2.4934\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 534ms/step - accuracy: 0.3088 - loss: 1.7412\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 552ms/step - accuracy: 0.3731 - loss: 1.5475\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 523ms/step - accuracy: 0.4005 - loss: 1.4799\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 525ms/step - accuracy: 0.4880 - loss: 1.3698\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 529ms/step - accuracy: 0.5485 - loss: 1.2581\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 579ms/step - accuracy: 0.5832 - loss: 1.1653\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 588ms/step - accuracy: 0.6290 - loss: 1.0877\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 575ms/step - accuracy: 0.6687 - loss: 0.9979\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step\n",
      "Rep:  4 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.7/female:0.3 | Acc: 0.39\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 490ms/step\n",
      "Rep:  4 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.6/female:0.4 | Acc: 0.44\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step\n",
      "Rep:  4 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.5/female:0.5 | Acc: 0.45\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460ms/step\n",
      "Rep:  4 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.4/female:0.6 | Acc: 0.46\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step\n",
      "Rep:  4 | Model: mobile net 2 | Feature Split: sex | Ratio: male:0.3/female:0.7 | Acc: 0.47\n"
     ]
    }
   ],
   "source": [
    "def perform_tests(df, train_meta, test_metas, reps, class_col, feature_split_col, exclude_column, files_col, get_model, epochs_num):\n",
    "    res = []\n",
    "    for r in range(reps):\n",
    "        train = get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=train_meta['ratio'], size=train_meta['size'])\n",
    "        tests = [\n",
    "            get_exp_data(df, class_col=class_col, feature_col=feature_split_col, ratio=tm['ratio'], size=tm['size'], exclude_column=exclude_column, exclude_df=train) for tm in test_metas\n",
    "        ]\n",
    "\n",
    "        train_dataset = get_data_for_model(train, class_col=class_col, files_col=files_col)\n",
    "        test_datasets = [\n",
    "            get_data_for_model(test, class_col=class_col, files_col=files_col) for test in tests\n",
    "        ]\n",
    "\n",
    "        #traind df ratios of sex column:\n",
    "        print(f\"Train ratios: {train[feature_split_col].value_counts(normalize=True).to_dict()}\")\n",
    "        #traind df ratios of dx column:\n",
    "        print(f\"Train class ratios: {train[class_col].value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "\n",
    "        model, model_name = get_model(num_classes=len(df[class_col].unique()))\n",
    "        model.fit(train_dataset, epochs=epochs_num)\n",
    "        \n",
    "        for test_dataset, test_meta, test_df in zip(test_datasets, test_metas, tests):\n",
    "            predictions = model.predict(test_dataset)            \n",
    "            y_true = test_df[class_col].astype('category').cat.codes.values\n",
    "            y_pred = np.argmax(predictions, axis=1)\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "            \n",
    "            test_ratio = '/'.join([f\"{k}:{v}\" for k, v in test_meta['ratio'].items()])\n",
    "            \n",
    "            res.append([\n",
    "                r,\n",
    "                model_name,\n",
    "                feature_split_col,\n",
    "                train_meta['size'], \n",
    "                '/'.join([f\"{k}:{v}\" for k, v in train_meta['ratio'].items()]),\n",
    "                test_meta['size'],\n",
    "                test_ratio,\n",
    "                acc,\n",
    "                f1\n",
    "            ])    \n",
    "\n",
    "            print(f\"Rep: {r:2} | Model: {model_name} | Feature Split: {feature_split_col} | Ratio: {test_ratio} | Acc: {acc:.2f}\")\n",
    "            \n",
    "            res_df = pd.DataFrame(res, columns=[\n",
    "                'rep', 'model_name', 'feature_split_col', \n",
    "                'train_size', 'train_ratio', 'test_size', 'test_ratio',\n",
    "                'accuracy', 'f1_score'\n",
    "            ])\n",
    "            \n",
    "            res_df.to_csv(f'res/res_{model_name}.csv', index=False)         \n",
    "        \n",
    "        \n",
    "perform_tests(df=df, \n",
    "              train_meta={'ratio': {'male':0.7, 'female':0.3}, 'size': 500},\n",
    "              test_metas=[\n",
    "                  {'ratio': {'male':0.7, 'female':0.3}, 'size': 100},\n",
    "                  {'ratio': {'male':0.6, 'female':0.4}, 'size': 100},\n",
    "                  {'ratio': {'male':0.5, 'female':0.5}, 'size': 100},\n",
    "                  {'ratio': {'male':0.4, 'female':0.6}, 'size': 100},\n",
    "                  {'ratio': {'male':0.3, 'female':0.7}, 'size': 100}\n",
    "              ],\n",
    "              reps=5,\n",
    "              class_col='dx',\n",
    "              feature_split_col='sex',\n",
    "              exclude_column='file_path',\n",
    "              files_col='file_path',\n",
    "              get_model=create_mobile_net2,\n",
    "              epochs_num=10\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79932277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+--------------+---------------------+------------+---------------+------+---------+\n",
      "|    | test_ratio          | Model        | TrainRatio          |   Accuracy |   AccuracySTD |   F1 |   F1STD |\n",
      "|----+---------------------+--------------+---------------------+------------+---------------+------+---------|\n",
      "|  0 | male:0.7/female:0.3 | mobile net 2 | male:0.7/female:0.3 |       0.42 |          0.03 | 0.41 |    0.03 |\n",
      "|  1 | male:0.6/female:0.4 | mobile net 2 | male:0.7/female:0.3 |       0.46 |          0.02 | 0.44 |    0.03 |\n",
      "|  2 | male:0.5/female:0.5 | mobile net 2 | male:0.7/female:0.3 |       0.46 |          0.02 | 0.45 |    0.03 |\n",
      "|  3 | male:0.4/female:0.6 | mobile net 2 | male:0.7/female:0.3 |       0.47 |          0.02 | 0.46 |    0.02 |\n",
      "|  4 | male:0.3/female:0.7 | mobile net 2 | male:0.7/female:0.3 |       0.48 |          0.02 | 0.46 |    0.02 |\n",
      "+----+---------------------+--------------+---------------------+------------+---------------+------+---------+\n"
     ]
    }
   ],
   "source": [
    "res = pd.read_csv('res/res_mobile net 2.csv')\n",
    "\n",
    "gr = res.groupby(['test_ratio']).agg(\n",
    "    Model=('model_name', 'first'),\n",
    "    TrainRatio=('train_ratio', 'first'),\n",
    "    Accuracy= ('accuracy', 'mean'),\n",
    "    AccuracySTD= ('accuracy', 'std'),\n",
    "    F1=('f1_score', 'mean'),\n",
    "    F1STD=('f1_score', 'std')\n",
    ")\n",
    "gr = gr.round(2).sort_values(by='test_ratio', ascending=False).reset_index()\n",
    "              \n",
    "print(tb.tabulate(gr, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
