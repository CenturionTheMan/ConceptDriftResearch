#### GAN'y -> używane do tworzenia Deepfake'ów

```
@article{goodfellow2014generative,
title={Generative adversarial nets},
author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
journal={Advances in neural information processing systems},
volume={27},
year={2014}
}
```

#### [Jak sie tworzy i wykrywa deepfake. Jakie zagrożenia powoduje. Do czego jest używany. Co się z tym może dziać w przyszłości.](https://arxiv.org/abs/2004.11138)

```
@article{mirsky2021creation,
  title={The creation and detection of deepfakes: A survey},
  author={Mirsky, Yisroel and Lee, Wenke},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={1},
  pages={1--41},
  year={2021},
  publisher={ACM New York, NY, USA}
}
```

#### [Zagrożenia związane z Deepfake'ami](https://scholarship.law.bu.edu/faculty_scholarship/640/)

```
@article{chesney2019deep,
  title={Deep fakes: A looming challenge for privacy, democracy, and national security},
  author={Chesney, Bobby and Citron, Danielle},
  journal={Calif. L. Rev.},
  volume={107},
  pages={1753},
  year={2019},
  publisher={HeinOnline}
}
```

#### [Wykrywanie Deepfake'ów (FaceForensics++). Porównanie różnych klasyfikatorów (Xception)](https://openaccess.thecvf.com/content_ICCV_2019/html/Rossler_FaceForensics_Learning_to_Detect_Manipulated_Facial_Images_ICCV_2019_paper.html)

```
@inproceedings{rossler2019faceforensics++,
  title={Faceforensics++: Learning to detect manipulated facial images},
  author={Rossler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1--11},
  year={2019}
}
```

#### [This survey paper provides a comprehensive overview of deepfake creation and detection methods, highlighting the growing threat posed by deepfake technologies and the ongoing efforts to combat them](https://arxiv.org/abs/1909.11573)

```
@article{nguyen2022deep,
  title={Deep learning for deepfakes creation and detection: A survey},
  author={Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Nguyen, Duc Thanh and Huynh-The, Thien and Nahavandi, Saeid and Nguyen, Thanh Tam and Pham, Quoc-Viet and Nguyen, Cuong M},
  journal={Computer Vision and Image Understanding},
  volume={223},
  pages={103525},
  year={2022},
  publisher={Elsevier}
}
```

#### [The paper underscores the importance of addressing bias and fairness in AI systems to prevent harm and ensure equitable outcomes. It calls for interdisciplinary collaboration and further research to develop robust, fair AI solutions.](https://arxiv.org/abs/1908.09635)

```
@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}
```

#### [Comprehensive textbook that explores the ethical, technical, and societal challenges of ensuring fairness in automated decision-making systems powered by machine learning (ML)](https://fairmlbook.org/)

```
@book{barocas-hardt-narayanan,
  title = {Fairness and Machine Learning: Limitations and Opportunities},
  author = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  publisher = {MIT Press},
  year = {2023}
}
```

#### [Bias w klasyfikacji zdjęć - przykład różnic w dokładności rozpoznawania płci ze względu na kolor skóry](https://proceedings.mlr.press/v81/buolamwini18a.html?mod=article_inline&ref=akusion-ci-shi-dai-bizinesumedeia)

```
@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}
```

#### [Algorytm do redukcji biasu z sieci bez modyfikacji zbioru danych. Polega na uczeniu i oduczaniu modelu](https://openaccess.thecvf.com/content_eccv_2018_workshops/w5/html/Alvi_Turning_a_Blind_Eye_Explicit_Removal_of_Biases_and_Variation_ECCVW_2018_paper.html)

```
@inproceedings{alvi2018turning,
  title={Turning a blind eye: Explicit removal of biases and variation from deep neural network embeddings},
  author={Alvi, Mohsan and Zisserman, Andrew and Nell{\aa}ker, Christoffer},
  booktitle={Proceedings of the European conference on computer vision (ECCV) workshops},
  pages={0--0},
  year={2018}
}
```

#### [Zbalansowany rasowo zbiór danych (zdjęć ludzi)](https://openaccess.thecvf.com/content/WACV2021/html/Karkkainen_FairFace_Face_Attribute_Dataset_for_Balanced_Race_Gender_and_Age_WACV_2021_paper.html)

```
@inproceedings{karkkainen2021fairface,
  title={Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation},
  author={Karkkainen, Kimmo and Joo, Jungseock},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1548--1558},
  year={2021}
}
```

#### [Sposoby na redukcje biasu (poprawę fairnes) poprzez modyfikację zbiorow uczących](https://link.springer.com/article/10.1007/s10115-011-0463-8)

```
@article{kamiran2012data,
  title={Data preprocessing techniques for classification without discrimination},
  author={Kamiran, Faisal and Calders, Toon},
  journal={Knowledge and information systems},
  volume={33},
  number={1},
  pages={1--33},
  year={2012},
  publisher={Springer}
}
```

#### [Usuwania biasu z sieci (np preferencji do uzywania rzeczowników w formie męskiej/żeńskiej)](https://arxiv.org/abs/1801.07593)

```
@inproceedings{zhang2018mitigating,
  title={Mitigating unwanted biases with adversarial learning},
  author={Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
  booktitle={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={335--340},
  year={2018}
}
```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```

####

```

```
